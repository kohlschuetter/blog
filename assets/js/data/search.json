[
  
  {
    "title": "junixsocket: Unix sockets API for Java; a long story short",
    "url": "/blog/posts/2023/08/06/junixsocket/",
    "categories": "Java, Linux",
    "tags": "junixsocket, java, linux, macos, kernel, sockets, af_unix, af_tipc, af_vsock, rmi, perplexity",
    "date": "2023-08-06 10:00:00 +0200",
    





    "snippet": "Prelude“It was the summer of 2009.” — that’s how I would have started this article. I would have spentsignificant energy in coming up with a few catchy paragraphs after that, before getting to the mainpoint.However, it is the summer of 2023, and, thanks to the advances in what some people used to callmachine learning, others black magic, and now collectively agreeing upon as “Artificial Intelligence”,a sizable portion of the human brain is now freed up to do other important things.So, let’s start this article the post-modern way, and show the output of the following prompt to perplexity.ai.  Write a short story about the summer of 2009, and how a Java developer decided to bring Unix domain sockets to that realm.Perplexity.ai writes, and I apologize profoundly for the length and content:  Once upon a time, in the summer of 2009, a Java developer named John was working on a project  that required interprocess communication (IPC) between two processes running on the same machine.  He was familiar with TCP/IP sockets, but he wanted a faster and more efficient way to communicate between the processes.  One day, John stumbled upon Unix domain sockets, which are like TCP/IP sockets but used only for local IPC. He was intrigued by the idea and decided to bring Unix domain sockets to the Java realm.  At first, John struggled to find a way to implement Unix domain sockets in Java. He searched online and found some libraries that claimed to support Unix domain sockets, but they were either outdated or didn’t work as expected.  Determined to find a solution, John decided to write his own library for Unix domain sockets in Java. He spent countless hours reading the Unix domain sockets documentation and experimenting with different approaches.  Finally, after several weeks of hard work, John was able to create a working implementation of Unix domain sockets in Java. He called his library “junixsocket” and released it as an open-source project on GitHub.  Over time, junixsocket gained popularity among Java developers who needed fast and efficient IPC between processes running on the same machine. Today, junixsocket is widely used in various Java applications, from web servers to desktop applications.Thanks to John’s hard work and dedication, Java developers can now enjoy the benefits of Unix domain sockets in their applications.Well, that was entertaining. OK, I know, for a fact, that John didn’t write junixsocket (but kudos for getting the name of the library right!) Let’s refine the prompt accordingly.Perplexity.ai, read my mind:Please,  Write a short story about the summer of 2009, and how a Java developer named Christian decided to bring Unix domain sockets to that realm.And the summoned did as I said:  Once upon a time, in the summer of 2009, Christian was a Java developer working on a project that required communication between different processes on the same system. He was frustrated with the limitations of TCP/IP sockets, which were the only option available at the time. He wanted a more efficient and secure way to communicate between processes on the same system.  One day, Christian stumbled upon Unix domain sockets, a type of socket that allows communication between processes on the same system using the file system as the transport mechanism. He was excited about the possibilities and decided to bring Unix domain sockets to the Java realm.  Christian spent the summer of 2009 working on a library that would allow Java developers to use Unix domain sockets in their applications. He faced many challenges along the way, including the lack of support for Unix domain sockets in the Java standard library and the need to write native code to interface with the Unix domain socket API.  Despite these challenges, Christian persevered and eventually released his library to the world. It quickly gained popularity among Java developers who were looking for a more efficient and secure way to communicate between processes on the same system.  Years later, in Java 16, Unix domain socket channels were finally added to the Java standard library, making Christian’s library obsolete. However, his contribution to the Java community will always be remembered as an important step towards more efficient and secure inter-process communication in Java.Welp, that was a bit too close to hurting my feelings; “obsolete” is a harsh word.Admittedly, some people may indeed see it so, but I am not here to indulge you with schmaltzy nostalgia about the good olden days where all we had was JNI and some brittle native C code.Inarguably, it is the summer of 2023 now, even Java 16 is a thing of the past, and machines have made writing articles so much more, let’s say, streamlined. And one can guess that, give it a few more summers, machines will be really good at writing Java libraries, too.One last chance, oh stochastic parrot that thou art in the cloud, reveal thy words, hast thou considered the following prompt:  Write a short story about the summer of 2023, and how a software engineer named Christian decided to keep working on this Java library for Unix domain sockets (which he started developing in 2009), despite being made obsolete with the introduction of unix domain socket support in Java 16.And so, the parrot twitters:  Once upon a time, in the summer of 2023, there was a software engineer named Christian. Christian had been working on a Java library for Unix domain sockets since 2009. He had put in countless hours of effort and dedication into developing this library, and it had become his passion project.  However, with the introduction of Unix domain socket support in Java 16, Christian’s library had become obsolete. The new built-in support provided all the functionality that his library offered, and it was now much easier for developers to work with Unix domain sockets in Java.  Christian was faced with a dilemma. He could simply abandon his library and move on to other projects, but he couldn’t bring himself to do that. He had poured so much of his time and energy into this library, and he believed that it still had value, even if it was no longer necessary.  Instead of giving up, Christian decided to continue working on his Java library for Unix domain sockets. He saw an opportunity to improve upon the existing functionality and make it even more powerful and user-friendly. He wanted to create a library that would provide additional features and capabilities beyond what the built-in support offered.  Christian spent the summer of 2023 tirelessly working on his library. He added new features, optimized the code, and made it compatible with the latest versions of Java. He also reached out to the developer community, seeking feedback and suggestions for improvement.  Despite the fact that his library was no longer essential, Christian’s dedication and passion for his work never wavered. He believed that there would always be developers who would appreciate the extra functionality and flexibility that his library provided.  As the summer came to an end, Christian released the latest version of his Java library for Unix domain sockets. It received positive feedback from the developer community, and many developers found value in the additional features it offered.  Christian’s decision to continue working on his library, despite it being made obsolete, taught him an important lesson about perseverance and following his passion. He realized that sometimes, even if something becomes unnecessary or outdated, there can still be value in pushing forward and striving for improvement.  And so, Christian’s journey as a software engineer continued, fueled by his unwavering dedication and love for his craft. He knew that there would always be new challenges to tackle and new opportunities to explore, and he was ready to embrace them all.Perplexity.ai, thou hast understood me well.MotivationYou have reached the limit for Perplexity-generated perplexities, not the end of the article.Yes, I had indeed started working on junixsocket in 2009. Mostly, because I wanted to use Java RMI between Java processes on the same machine. I had built a service-oriented architecture for the reboot of my news search engine, NewsClub. I got it working to the point where it worked for me, and perhaps some others, so I felt it should be released to the world as open source, giving back a little of what I took to use elsewhere in my codebase. And so it remained online as it was.Years go by. NewsClub never restarted, for reasons beyond the scope of this article. I sought employment at-will, and certain terms of employment, although of questionable chance of enforcement, were imposed upon me as I continued my career. They made it clear that I’d better stay off developing open source software in my spare time.Now that I am unshackled again, again for reasons beyond this article but under my control, I decided to double-down on my journey of dedication and love for the craft.I also learned that, no, Java 16’s introduction of support for Unix domain sockets isn’t remotely signaling the end for junixsocket…Interoperability with existing codeFor one, the new Java 16 API only provides SocketChannel/NIO access, not Socket, and only streams, no datagrams. It also makes integrating the new abilities into existing code extremely difficult: Most Java code that deals with “Internet” sockets, such as Java RMI, works with InetSocketAddress-es, which were designed for IP (TCP, UDP, etc.) addressing and communication. The Java API creators took great care of encapsulating the already encapsulating BSD socket API even further. It was tailored towards IP communication.junixsocket works with these idiosyncracies, allowing for a very smooth transition to Unix domain sockets for existing code.Because of junixsocket’s design, we can, for example, easily reuse code for HTTP servers and clients (using a variety of implementations, even including Jetty, and serve content over UNIX domain sockets (or “AF_UNIX” with AF standing for address family). We can also use it to connect from Java (or any other JVM language) to a PostgreSQL or MySQL server over the socket file in the file system, instead of relying on local TCP/IP communication that could open up a security hole.We can also make use of features not supported by Java 16’s native support of Unix domain sockets, such as passing file descriptors from one process to another. Remember, file descriptors can be anything, like referencing another socket, potentially created in a process with elevated privileges, being passed down to one that is more restricted.Interoperability with other socket domainsNow, for the second important point. Unix domain sockets aren’t the only “Unix sockets” (BSD sockets, POSIX sockets, how you want to call them).There are very interesting protocols out there that really wait to be made accessible from a high-level language like Java, for example: VSOCK (communication between a VM, its host and maybe its peers), TIPC (high-availability communication in a cluster environment), and even things like AF_SYSTEM on macOS, which allows talking to kernel-level features like creating VPNs (with junixsocket, a Java-only WireGuard implementation on macOS may be just around the corner).junixsocket exposes these protocols in a way that feels like the proper Java-way.For example, with junixsocket it’s trivial to serve websites over TIPC, in other words building your own high-availability HTTP cluster has never been easier.Interoperability with different platformsThis last point is critical. We could have just exposed the low-level BSD socket API as-is, but you would be in for a bag of surprises if it wasn’t for junixsocket to shield you from the specifics of how certain operating systems interpret these APIs.I’ve taken great care of building a suite of integration tests (“junixsocket-selftest”) that can be run on any supported platform, helping me find the rough edges of a system. I’ve also added a set of “capabilities” that a developer can check against to see if these are supported in the environment their code runs in. Both measures help determine the suitability of junixsocket before one actually runs into a problem while in production.As a recent example, thanks to junixsocket-selftest, we were able to detect three bugs in the Haiku operating system, one being a bug around socket addresses, one around the “buffer-full” condition, and even one being a use-after-free bug that crashed the kernel.I’ve also ventured into supporting mainstream and niche platforms alike, such as Linux, macOS and the BSDs (FreeBSD, OpenBSD, NetBSD, DragonFlyBSD), Solaris/OpenIndiana, Windows, Android, GraalVM, IBM’s operating systems AIX, IBM i, z/OS, and perhaps even z/TPF (for TPF, I have a working binary but no system to test with…). They all have their delicate intricacies, and while it was fun building support for them, it’s something someone else should be able to ignore and take for granted.Lastly, junixsocket runs with Java 8 or newer. So even if you’re stuck in the past, junixsocket will help you out.How the Sausage is MadeRealizing that this article already has a lot of words, today I want to spare you from the details of how all this is put together; such prose is for another day, unless you want to add junixsocket as a project dependency, dive right into the source code or ask the perplexing oracle.I admit I enjoyed building junixsocket not only for the why and what, but also for the how of all this fitting together, for the craft itself.What I will do today in this article is to stay high-level; further details, only sketched below, warrant their own blog posts. I will update this article with links once they are published.The junixsocket package builds entirely on my Apple Silicon MacBook Pro, cross-compiling most supported target platforms out-of-the-box (as of version 2.7.0 twenty-four platform/architecture-specific binaries are included).The build process, which is mostly based on Maven, constructs Java multirelease jars (with certain optimizations only available for newer Java versions), in probably the only sane and Eclipse-compatible way I’ve seen so far, supplying the JNI library without much further ado as a jar in the classpath/modulepath, Jigsaw-aware and all.During that build time, numerous static code checkers, such as Checkstyle, Spotbugs and PMD (and occasionally, Google’s errorprone and Facebook’s infer) regularly tell me how stupid I am, before making me fix the code, and automatically reformat everything so neatly that bikeshedding in code reviews, even as soliloquy, becomes practically impossible.Furthermore, I won’t bother you (yet) about how junixsocket appears to be faster than Java 16’s API in some cases (I don’t yet know why), or how JNI can be useful even in the days of Project Panama, which junixsocket is certainly going to explore in a future version.A Shameless PlugThere is no paywall, no monetary obligation; junixsocket is Apache 2.0 licensed open source. So what am I asking for?Having just released junixsocket version 2.7.0, I would like you to try it out, maybe again, and learn its many uses that reveal themselves only if you are truly invested in this excitingly deep niche interest.Please visit the junixsocket website and have a look at its public repository on GitHub. If you have questions, don’t hesitate asking them.If you find junixsocket is not useful for you, let me still thank you for allowing me to share with you the knowledge that this library exists.Nervertheless, perhaps you find that junixsocket lacks a feature that you (or Perplexity.ai) would like to see included?If so, give me a holler, send me a packet of demands over your favorite protocol.Yours connectedly,Christian Kohlschütter"
  },
  
  {
    "title": "NanoPi R4S — On booting mainline Linux, fixing SD-card support, and a Heisenbug that sucked me into a rabbit hole",
    "url": "/blog/posts/2022/10/28/linux-nanopi-r4s/",
    "categories": "Linux",
    "tags": "linux, kernel, patch, arm64, nanopi-r4s",
    "date": "2022-10-28 14:00:00 +0200",
    





    "snippet": "I bought this little ARM64 single-board computer. Getting it to work reliably with amainline Linux kernel dragged me into the world of device trees, voltage regulators, and one of theworst Heisenbugs I encountered so far.  My NanoPi R4S, connected to a well-regulated arsenal of otherdevices There’s quite the market for ARM-powered single board computers with Rockchip, Amlogic, Allwinner,Broadcom, and other system-on-chip (SoC) brands at its heart.  The materialized promise of anaffordable, energy efficient but well perfoming system at an affordable price, suitable for avariety of tasks, ranging from sensor controls over home automation, TV media centers, networkattached storage, to machine learning applications.  An exciting prospect.Depending on what device you buy, you may or may not get excellent support from the manufacturer, anonline community, or maybe even books and magazines with step-by-step instructions.  In many cases,the device isn’t fully supported by the “vanilla” Linux kernel, so you’re either stuck with some oldkernel build or, by using a newer mainline kernel,you miss out on some features and performance optimizations that haven’t been upstreamed yet.Out of interest, I’ve bought a few such devices in the sub-$100 range to play with.  One thatrecently caught my attention is the FriendlyELEC NanoPiR4S, a tiny devicepowered by a Rockchip RK3399 CPU, supplied with 4GB RAM, a Micro-SD card slot, two USB 3.0 ports, and, most important to my needs, two GigabitEthernet ports: I want to build a Linux router that can hide some of my development servers behind afirewall, accessible via VPN, and with enough headroom to run a few other services like a web serveror file server.  I guess if limited RAM wasn’t an issue, an old Wifi router would also be sufficientfor that task.  OpenWRT is a great software solution for this use case.When I got the device, OpenWRT was actually the first thing I tried running.  OpenWRT provides a lotof good documentation around a variety of boards, including theR4S.  There’s also an OpenWRT forum thread forthe R4S, which provides further tips andtricks,such as improving Ethernet throughput.  I can confirm that the R4S reaches and even surpasses the934 Mbps claimed byFriendlyELEC.I know, FriendlyELEC has their own fork calledFriendlyWRT, and they seem to provide some goodguidance and documentation on how to runthat or their Ubuntu fork FriendlyCore on the machine.  Personally, however, I prefer to havecritical systems be as close as possible to upstream, the mainline Linux kernel and a majordistribution so their forks just aren’t an option for me.  I could only hope that any featuresmissing upstream will eventually be ported there.Getting things to work once is one thing, getting them to work reliably in a maintainable way ismuch harder than one may think.  Especially when it comes to ARM-based single board computers.  Why?Because, very much unlike older x86 systems with BIOS or EFI, the entire boot process, fromdetecting RAM and storage, setting CPU clock and voltage, loading the kernel, over detectingbuilt-in and external devices to actually being able to reboot the system are pretty much different(read: wildly incompatible among SoC manufacturers).Therefore, when you download OpenWRT, you have to find the exact system image suitable for your ARMboard, or your system won’t boot.  The R4S isn’t fully supported yet by a release-quality version ofOpenWRT, but at least a so-called “snapshot” build (read: unstable) is available for tinkering.  Alot of hard work went into supporting these systems, and OpenWRT does a great job documenting thesedevices.Thanks to these efforts, setting up the device was relatively easy, despite it being of “snapshot”quality: Download an image file and write that onto a MicroSD card.  The R4S boots up OpenWRTquickly, and, once connected to Ethernet, can be configured via ssh and a web browser.Unfortunately, I wasn’t able to get the second Ethernet port to work, it just wouldn’t let me sendor receive any data since that was a hard requirement for my use case, I started exploring theoption: run a “proper” Linux environment.This is the point where things got interesting, because it got me off the beaten path.  In order toboot some existing Linux distribution like my favorite, Alpine Linux.It does exist for ARM64 but doesn’t yet support booting from my NanoPi R4S.  All the heavy lifting apackage like OpenWRT already needs to be replicated.  Thankfully, this provided me with an excitingopportunity to learn more about the entire boot process than I ever wanted to know.In a nutshell, to boot Linux off an ARM board, you need a series of “boot loaders” that initializethe board and load the kernel from disk.  As I said earlier, this is very much non-standard, andevery chipset’s and manufacturer’s approach is a little different here.  I’m going to skip over alot of details around that because this post really isn’t about the boot loader, it’s about whathappens when you think you got it working to the point where the Linux kernel starts up.A common boot loader for ARM boards is “Das U-Boot”.  Usually,vendors ship an outdated build with a certainconfiguration, tweaked to make it “just work”.Using U-Boot from mainline source involves a few more steps, and all I can say is I’m happy I got thatpart working as well.When I finally managed to boot the Linux 5.19 kernel from U-Boot, I was greeted with a crypticmessage about problems in the Linux kernel’s MMC subsystem, which is responsible for accessing theSD card:    mmc1: problem reading SD Status register    mmc1: error -110 whilst initialising SD cardBeing unable to boot the kernel off the SD card, I looked into booting over the networkusing IPXE, a boot loader I had experimented with for an earlier project.So my plan was to get U-Boot to boot IPXE, which would download a script from a local server thatwould then boot Linux.  Piece of boot, err, cake!  Whatever MMC bug there was, I would not beblocked by it because now there was no need to access the SD card from Linux; everything would beloaded from the network directly into RAM.  As an additional benefit, debugging the MMC bug wassimplified, now that even the Linux kernel gets loaded off the network: I wouldn’t have to jugglewith the SD card(or use an USB-device that can simulate one).Ejecting the card from the NanoPi, inserting it into a working computer, writing a new kernel to it,then again ejecting and reinserting the SD card: thanks to networking booting, all that was nolonger necessary.  All I needed was another (faster) machine to build the Linux kernel, then storethe kernel binaries on the server that IPXE picks up from.  I would then “simply” have to pokearound the kernel code, rebuild it on the other computer, and then reboot the NanoPi over ssh untilthe MMC bug was gone.  Or so I thought, because rebooting the NanoPi just didn’t work either!The NanoPi-R4S would alternatingly just hang upon reboot (after reboot: Restarting system) or, ifI was “lucky”, reboot back to U-Boot but then get stuck with another MMC related error:    Trying to boot from MMC2    mmc_load_image_raw_sector: mmc block read error    SPL: failed to boot from all boot devices    ### ERROR ### Please RESET the board ###After analyzing several patches thatdistributions typically add for Rockchip boards, I found this littlegemfrom 2019.  It hasn’t been merged to mainline, but it’s commonly included by distributions to thisdate.  The change mentions that newer SD cards (“UHS Ultra-High-Speed”) would use a different signalvoltage (1.8V) than older SD cards (3.0V) and that U-Boot expects the MMC/SD card system to be in3.0V mode and would just hang if that unexpected condition was hit.  So one workaround would be toget a non-UHS SD card, but that’s no solution.The patch works around the U-Boot bug by setting the signal voltage back to 3.0V at an opportunemoment in the Linux kernel upon reboot, before control is relinquished back to U-Boot.  I learnedthat the signal voltage is controlled by a “voltage regulator” component that is controlled via aspecific GPIO (“general purpose I/O”) pin.  Note that, at this point, I was in waters very muchunknown to me.  I didn’t really know much about this hardware stuff at all, but it was veryfascinating to learn that I was not alone.The way the Linux kernel knows about all these configurations, regulators, I/O memory addresses,etc., is typically done with “device trees”, configuration files that are SoC- and board-specific.It turns out the Linux kernel doesn’t really want to bother at all with the detail decisions an ARMboard manufacturer makes when putting together a single board computer, like which GPIO pin maps towhich function, be it the SD card voltage, the power and activity LEDs, and so on.  The devicetree configuration takes care of the heavy lifting.  This in turn reduces the need of a customkernel fork patched by the SoC vendor; long-running forks are really quite hard to maintain.Device trees (or: devicetrees) are compiled into abinary using the “device tree compiler”, using sources files that are declarative in nature, lookinglike C and JSON had an extramarital affair.  The device tree files are included with theLinux kernel (and also U-Boot) but also need to be specified upon boot, which means the kernelbinary can be reused among different boards but won’t function correctly unless the correct “dtb”(device tree blob) is specified as a kernel boot parameter.  Using a custom dtb can overclock,undervoltage or simply brick your device.  So much power in a little file.Understanding what configuration gets actually used is a bit tricky when studying the source code:the device tree compiler supports preprocessor includes, meaning that there are several sourcesshared among a family of boards and chipsets, with subtle differences in the final configuration:defaults can be overridden for a specific board, naming conventions vary even for boards with thesame CPU but different vendors, and so on./dts-v1/;#include &lt;dt-bindings/input/linux-event-codes.h&gt;#include \"rk3399.dtsi\"#include \"rk3399-opp.dtsi\"/ {    //...    vcc3v0_sd: vcc3v0-sd {        compatible = \"regulator-fixed\";        enable-active-high;        gpio = &lt;&amp;gpio0 RK_PA1 GPIO_ACTIVE_HIGH&gt;;        pinctrl-names = \"default\";        pinctrl-0 = &lt;&amp;sdmmc0_pwr_h&gt;;        regulator-always-on;        regulator-min-microvolt = &lt;3000000&gt;;        regulator-max-microvolt = &lt;3000000&gt;;        regulator-name = \"vcc3v0_sd\";        vin-supply = &lt;&amp;vcc3v3_sys&gt;;    };    //...   };   A snippet from the devicetree configuration for RK3399 NanoPi devices,showing the SD-card voltage regulatorWhen I compared the devicetrees of certain RK3399 boards, I noticed that the GPIO pins used for theSD card voltage regulator varied, certain parameters were missing in some configs, and some configshad extra parameters that I hadn’t seen elsewhere.After a bit of trial and error, such as deliberately using the wrong device tree (which I wouldn’trecommend doing since it could damage the board), the system would boot up without problems.  Withthe one kernel patch mentioned above, it would also not hang upon warm-booting U-Boot.  I was up tosomething!I thought that I had found the reason why the device wasn’t working properly: I assumed that thedevicetree config for R4S just had the wrong GPIO pin configuration, and since changing it to theone I had found in the other devicetree fixed it, I thought it was the end of the story.So I followed my civic duty and submitted apatchto the Linux kernel mailing list: “arm64: dts: rockchip: Fix SD card init on rk3399-nanopi4”.This in turn sucked me deeper into the rabbit hole of SD cards, GPIO pins and voltage regulators.Remember, all I wanted was to get my NanoPi R4S boot up Linux without errors.My patch changed the GPIO pin for the SD-card voltage regulator vcc3v0-sd from RK_PA1 toRK_PD6, which I had seen in the other RK3399 DTS file (rk3399-roc-pc.dtsi for the FireflyROC-RK3399-PC), and it worked.But it didn’t work for the right reason, as I learned from the helpful replies on the kernel mailinglist.  My patch was actually just pointing the regulator at a non-existant GPIO, and thus, thekernel would just do nothing with that voltage regulator.  In other words, U-Boot had set up thevoltage correctly, and the kernel just wouldn’t even try to do anything else with it.  So, the patchwasn’t a fix, it was just a happy accident.  I then understood that “RK_PD6” doesn’t refer to aspecific GPIO pin; the GPIO number preceding it was also important (&amp;gpio0), since there aremultiple GPIO banks, and I just happened to change it to something that worked.Removing the line declaring the GPIO pin would also “work”, but definitely be no viable option forthe kernel maintainers: the Linux kernel would just lose the ability to control the voltageregulator entirely, even if that unbroke some aspect of its main purpose.So how does one know what the right GPIO pin is and how this all works together?  Well, you can seethe devicetree configuration as a derivative or simplified form of the board/SoC schematics.Thankfully, most schematics are available online, even though you may have to put a few puzzlepieces together.FriendlyELEC thankfully provides the schematics for the NanoPi R4S as a searchablePDF, andsearching for VCC3V0_SD yields two matches:  NanoPi R4S schematics: GPIO0_A1 isan RK3399 GPIO pin, controlling the SDMMC0 power There’s also a match for the pinctrl reference sdmmc0_pwr_h:  With NanoPiR4S, the SDMMC0 power is fed from a 3.3V power source (`VCC3V3_SYS`) and controlled using an RT9193 \"Ultra-Fast CMOS LDORegulator\" I’m not totally sure how this works in detail. I can’t quite understand the schematics, but I thinkit’s fair to say that the 3.0V (VCC3V0_SD) can be toggled on/off, whereas the 1.8V (I have no ideawhich power rail it is) are always connected to an SD-card pin that is only present on UHScards.In any case, I find it rewarding that I now somewhat better understand how these things areconnected.  For a generally better explanation from a generally better person, be sure to check outLouis Rossmann’s 15 minutes about power rails, andwatch till the end for a relevant rabbit metaphor.Equipped with this understanding about how RK3399 boards control the power for SD-cards, I think Ican claim that the &amp;gpio4 RK_PD6 GPIO_ACTIVE_HIGH reference for vcc3v0_sd inrk3399-roc-pc.dtsi is wrong.  In the corresponding, and sadly, quite incomplete technicaldocument for that board,I couldn’t even find a reference to GPIO4_D6.  Since I don’t own such a Firefly board, I can’t speakmore to it but my guess is that any RK3399 configuration that uses any GPIO other than GPIO0_A1 iswrong; that pin is used by RK3308 SoCs (calledSDMMC_PWREN) and maybe really is just acopy-paste typo.  And it works just the same way my original patch “worked”: by luck.  (EDIT:Markus Reichl pointed me at another schematic PDF for the Firefly ROC-RK3399-PC which indicates that theyindeed use GPIO4_D6 for their voltage regulator – so another lesson learned: get any availabledocumentation for your board and get comfortable dealing with incomplete or even conflicting specs).Back to my Linux kernel mailing list thread, Robin Murphy from ARM helped to better put the problemin context.  My issue reminded him of the “Tinkerboard problem” (which certainly sounds better thanmy “R4S situation”), where the signal voltages for the SD card were indeed at the wrong level (1.8Vvs 3.0V).  In fact, the patch I had found earlier was exactly the remedy for that it fixed thereboot-to-u-boot case but obviously not everything.Robin further explained that the issue I’m seeing could be a slow voltage regulator at fault on myparticular board.  Yes, it turns out there’s such a thing as “slowness” in the digital-analog realmof modern computing!Setting a GPIO pin from 0 to 1 doesn’t mean the effect is immediate.  The connected regulator mayneed hundreds of microseconds or even milliseconds to reach and stabilize the desired voltage aneternity in relative terms where CPU operations usually take nanoseconds (i.e., a billionth of asecond).  Be sure to see this demonstration byAdmiral Grace Hopper for an amazing visualization of nanoseconds.Robin was kind enough to hook up an oscilliscope to measure the regulator voltage change of hisRK3399-powered NanoPC-T4 (not quite my R4S, but close enough).  It turns out it takes around 160microseconds to truly reach the destination voltage (which is not nothing, and definitely more thanthe 50 microseconds we see in the regulator specs, although the voltage is “roughly” right afterthat time), but he didn’t see any problems on the MMC driver side even when cycling (unbinding andrebinding to re-trigger the regulator). Oscillator plot showing a 161 us delay until the regulator voltage settles; courtesy ofRobin Murphy Captivated by this insight, the neither-owning-nor-knowing-how-to-use-an-oscilloscope-me tried tolook for devicetree configuration options that may “properly” fix the issue. After all, lookingthrough the documentation, there is a variety of parameters to play with.I stumbled upon theregulator-uv-protection-microvoltdevicetree option, which is supposed to guard against undervoltage situations, something that wasclose enough to merit an experiment.  When I set the undervoltage value to 3.0V and rebooted themachine, Linux would suddenly no longer fail detecting the SD-card!Well, except when I tried a couple more times, it actually did fail again.  I then assumed that —sigh — this is deep in analog territory, and 3.0V might be just too high of a limit, so let’s trythe minimum voltage SD cards are supposed to handle, which is 2.7V, and, indeed, a couple morereboots continued to show my intuition was right.  At least until I submitted the revised patch…When Robin thankfully chimed in again, it was clear that something else was at play here.  Well this has to be in the running for “weirdest placebo ever”… :/It turns out that the R4S’s voltage regulator is not very complex, and in fact not capable ofbeing controlled against undervoltage. So the new devicetree setting was again somehow changingthe parameters that triggered the problem, but it was no solution. Robin quipped this had to berunning for the “weirdest placebo ever”.Robin clarified that all this setting did was to write a warning to the kernel log(“IC does not support requested under voltage limits”), Maybe, he assumed, the regulator was beingturned off and on again by regulator code, and that writing that linetook long enough to be a proper delay to have the regulator reach its target voltage.Equipped with an oscillator, Robin was actually able to verify his hypothesis!  …and apparently the answer is yes, it seems to be doing exactly that (see attached).   But seemingly my SD cards don’t mind, or maybe my T4 board happens to have more capacitance   than Christian’s R4S so my voltage dip isn’t as bad, or both. Oscillator plot showing an intermittent voltage drop caused by double-toggling; courtesyof Robin Murphy That brought us closer to understanding what was going on.  I felt both very unlucky (R4S board withlow capacitance, maybe the wrong SD card) and very excited at the same time!  The “proper” solutionwas close.Robin suggested to remove theregulator-always-onstatement from the devicetree setup, which means Linux would not try to toggle the regulator untilthe MMC driver actually needed it.  Removing a line instead of adding anything new, I like that!Unfortunately, even with the “tinkerboard” patch this change broke rebooting the machine…  Withoutthe regulator-always-on, the kernel tries to deactivate the voltage regulator before rebooting,and that somehow causes the system to lock up.On the other hand, we had a fix.  Robin’s initial hunch that hardcoding a delay in the regulatorsetup code (set_machine_constraints) was correct and working, and practically identical tospecifying a devicetree setting,off-on-delay-us.Of course, fixing the devicetree instead of the kernel means we could unbreak existing kernels bysupplying them with a new blob, which could be preferable over requiring an upgrade to the bleedingedge.  off-on-delay-us adds a specific, constant delay, so a quick toggling of the regulator wouldnot cause the observed glitch.  This sounds like it’s the right approach since the delay is handledby existing kernel code, even the most basic voltage regulator will support it:            vcc3v0_sd: vcc3v0-sd {                off-on-delay-us = &lt;160000&gt;;The proposed change to the NanoPi configurationExcept, I found, that delay is not honored in our case!Deep in the kernel’s regulator code, whenever a regulator is turned off, a “last off” timestamp isupdated (and then later checked against the current time) except when the regulator is marked as“always on” or “boot-on” (= “bootloader has enabled it already, but we can turn it off”).  Omittingthe last-off assignment in that case seems like a reasonable micro-optimization, but it actuallyfails to capture the quick toggling that Robin observed with the oscilloscope.So even though we have a bouquet of configuration options for the devicetree, presently it lookslike we have to patch the kernel.I submitted a patch to remedy theoff-on-delay bug, and it thankfully got merged into linux-next in time for the Linux 6.0 release.Looking deeper into why there was a double-init, toggle or something like that around theset_machine_constraints code in regulator core, I added several debug log statements to see whatregulator was initialized when and how.  Yes, debugging byprinting is the way to go here.A couple of hard reboots later I had figured it out.  Until then, I had connected the R4S to aswitchable USB hub the R4S doesn’t have a power button, and yanking the cable out every time Ineeded a restart lost its appeal about 5 hours into this chase.  I already thought about automatingthis toggle as well.  This probably would’ve lead me deeper into the rabbit hole, making me hook upan ESP32 USB relay for the power supply so I could debug this situation without having to walk up tothe device at all.  Alas, that’s for another project.Back to the regulator code, drivers/regulator/core.c to be specific.  There are several mentionsof issues resolving supply names early (since a voltage regulator is supplied by voltage coming fromsomewhere else — probably another regulator — the kernel needs to do this in an efficient way).  Mydebugging has shown that, with the existing regulator initialization code, we indeed togglevcc3v0-sd twice in rapid succession!  Furthermore, if we initialized supply names and constraintsa little earlier in the registration code, a double-initialization can be avoided, and we can stopworrying about the off-on-delay and its implications on devicetree configurations!That patch, “regulator: core: Resolve supply name earlier to prevent double-init” (early discussionhere,and here)has been merged for 6.1as well.My understanding is that my fixes are addressing issues that are not specific to my NanoPi R4S atall.  There’s a good chance that other hard-to-reproduce issues, maybe around certain MMC/SD cardson other boards, or entirely different areas where voltage regulators are cycled too quickly, arenow suddenly fixed.  We may never know.This excursion took way longer than anticipated, yet it was truly rewarding for me in several ways.Not only did I learn a lot of new tricks at the very low level intersection of ARM hardware and thekernel, I also really enjoyed working with the kernel community to come up with a solution that notonly “works for me” but would be the proper fix, resulting in several patches that are likely to beincluded in the upcoming Linux 6.1 release.Lastly, it made me doubt my ability as a software engineer, in a good way.  Bugs like these,Heisenbugs, the ones that change their behavior at theslightest observation or attempt to fix them (such as adding a debug log line or specifying a newparameter, are rare, but they are a humbling reminder that all your time spent on them is especiallyworth it.  Somewhere, someone (who would have just given up or bought a slower SD card instead) cannow enjoy their new ARM computer a little more, and this satisfying thought will let me sleep alittle better tonight."
  }
  
]

